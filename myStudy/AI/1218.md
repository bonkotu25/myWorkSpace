# AI技術要素メモ

## はじめに

- 気軽に聞いてね。
- わからないことや知りたいことは情報もらえると私も調べます。

## 前回のおさらい

- Claude Opus4.5がでました。
- Antigravity

## 話したいこと

- GPT-5.2がリリース[参考]([参考](https://openai.com/ja-JP/index/introducing-gpt-5-2/))
  - GPT-5.1をベースに性能を強化(推論能力、コンテキスト、ツール連携、画像周り)
  - GDPバル(経済的価値のある実世界の知識労働タスク)が38% → 70%に
  - 日本語換算で数十万〜100万文字規模のコンテキスト長
- コンテキスト長問題について[参考](https://zenn.dev/chameleonmeme/articles/989ccef3027419)
  - コンテキスト長とはなにか
    - LLMに入力するトークンのinputのサイズ
    - 文字数ではなく、トークン数で計算する。
  - コンテキスト長問題とはなにか。
    - コンテキストを長くすると計算量が増加する(O(n<sup>2</sup>))
    - コンテキスト長が大きくなると、LLMのパフォーマンスが大幅に劣化する。（ハルシネーションが発生する。）
  - コンテキスト長が大きいと何ができるのか
    - 記憶力・理解力
      - 過去の会話の流れを記憶できるため、長い対話での出力精度が向上する。
    - 処理能力
      - より多くの情報を処理することができる。
    - 精度向上
      - 文脈の全体像を把握できるので応答の精度が向上する。
  - コンテキストがあふれると何が起こる？
    - auto-compact（自動要約機能）
      - 累積のトークンが閾値を超えたらチャット履歴を自動的に要約し、差し替える
      - コンテキストの損失
- Claude Codeでできること ※[参考](https://zenn.dev/flinters_blog/articles/711ff6faeca62c)
  - CLAUDE.md(全体ルール)
    - cursorでいうところのプロジェクトルール
    - システムの全体像や前提となる部分のインプットを記載する
  - Slash Commands
    - ユーザーが独自のコマンドを作れる。例：レビュー用コマンドなど
    - 繰り返し発生する定型作業の負担を減らし、出力を安定させることができる。
  - Sub-Agents※[参考](https://zenn.dev/tacoms/articles/552140c84aaefa)
    - コンテキストウィンドウを分離させて別タスクとして作業をさせる。
    - 例)同じコンテキストで作業をしていると関係ない作業をやらせたときにその作業でコンテキストが汚れてしまう。→ Sub-Agentsで処理を分離させることで、コンテキストを汚さずに作業させることができる。
  - Hooks
    - イベントハンドラ。イベント駆動なので確実に起動させることができる。プロンプトに問わず確実に実行させることができるのでログ出しなどに使える。
  - Plugins ※[参考](https://zenn.dev/canly/articles/965cc8e7e9be8d)
    - ユーザーが自作したスラッシュコマンドなどを共有することができる。チームの環境統一などに使用できる。
  - Agent Skills
    - AIで判断して必要な部分だけを読み込むことができる。前提知識や設定などでコンテキストが溢れないようにできる。
    - 通常は全体ルールやMCPもコンテキストに含まれてしまう。そのため、本当にやりたいことを実施する前にコンテキストが溢れてしまう。
    - スキルとして定義されたフォルダを参照して、余計な情報は読み込まないようにしてコンテキストがあふれるのを防ぐ。


